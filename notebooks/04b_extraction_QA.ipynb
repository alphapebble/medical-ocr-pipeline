{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52614118",
   "metadata": {},
   "source": [
    "# 04b — Extraction QA (Inputs & Valid Chunks)\n",
    "Verifies integrity of input blocks and chunked valid outputs from 04a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a011f843",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_root = \"outputs/run_001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91505a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "run_root = Path(run_root).expanduser().resolve()\n",
    "in_candidates = [run_root / '03_llmcleaned', run_root / '02_cleaned', run_root / '01_blocks']\n",
    "in_dir = None\n",
    "for c in in_candidates:\n",
    "    if any(c.glob('page_*_blocks*.json')):\n",
    "        in_dir = c\n",
    "        break\n",
    "if not in_dir:\n",
    "    raise FileNotFoundError(f'No input blocks found under {run_root}')\n",
    "\n",
    "valid_dir = run_root / '04_jsonextracted'\n",
    "if not valid_dir.exists():\n",
    "    raise FileNotFoundError(f'Valid-chunk folder not found: {valid_dir}')\n",
    "\n",
    "print(f'[QA] Inputs  → {in_dir}')\n",
    "print(f'[QA] Valids  → {valid_dir}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd169bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = sorted(in_dir.glob('page_*_blocks*.json'))\n",
    "print(f'[QA] Found {len(pages)} input page files')\n",
    "for p in pages:\n",
    "    try:\n",
    "        data = json.loads(p.read_text(encoding='utf-8'))\n",
    "        if not isinstance(data, list):\n",
    "            print(f'[WARN] {p.name}: not a list (type={type(data).__name__})')\n",
    "            continue\n",
    "        n = len(data)\n",
    "        sample = data[0] if n else {}\n",
    "        keys = list(sample.keys())[:6] if isinstance(sample, dict) else [type(sample).__name__]\n",
    "        print(f'  ✓ {p.name}: {n} blocks, sample keys={keys}')\n",
    "    except Exception as e:\n",
    "        print(f'[ERROR] {p.name}: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c127e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coerce_to_list_of_dicts(obj):\n",
    "    if obj is None: return []\n",
    "    if isinstance(obj, str):\n",
    "        s = obj.strip()\n",
    "        if not s: return []\n",
    "        try: obj = json.loads(s)\n",
    "        except Exception: return [{'_raw': s}]\n",
    "    if isinstance(obj, dict): return [obj]\n",
    "    if isinstance(obj, list):\n",
    "        return [x if isinstance(x, dict) else {'_value': x} for x in obj]\n",
    "    return [{'_value': obj}]\n",
    "\n",
    "valids = sorted(valid_dir.glob('*_valid_*.json'))\n",
    "print(f'[QA] Found {len(valids)} valid chunk files')\n",
    "total = 0\n",
    "for f in valids:\n",
    "    try:\n",
    "        obj = json.loads(f.read_text(encoding='utf-8'))\n",
    "        rows = coerce_to_list_of_dicts(obj)\n",
    "        total += len(rows)\n",
    "        sample = rows[0] if rows else {}\n",
    "        keys = list(sample.keys())[:6] if isinstance(sample, dict) else [type(sample).__name__]\n",
    "        kind = type(obj).__name__\n",
    "        print(f'  ✓ {f.name}: {kind}, {len(rows)} records, sample keys={keys}')\n",
    "    except Exception as e:\n",
    "        print(f'[ERROR] {f.name}: {e}')\n",
    "print(f'[SUMMARY] Total records across valid chunks: {total}')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
