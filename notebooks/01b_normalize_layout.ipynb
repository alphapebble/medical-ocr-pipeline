{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "381d3798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ page_001_blocks.json: in=8 out=6 chars=2155/2153 (100.1%) tagged(H/F)=0/0 mode=1col\n",
      "✓ page_002_blocks.json: in=12 out=11 chars=4099/4098 (100.0%) tagged(H/F)=0/0 mode=2col\n",
      "✓ page_003_blocks.json: in=8 out=6 chars=1642/1642 (100.0%) tagged(H/F)=0/0 mode=1col\n",
      "✓ page_004_blocks.json: in=9 out=8 chars=1901/1900 (100.1%) tagged(H/F)=0/0 mode=2col\n",
      "\n",
      "✅ Layout normalization complete → /Users/balijepalli/Documents/GitHub/entheory-ai/notebooks/outputs/run_001/01a_normalized\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# 01a — Normalize multi-layout structures (fixed)\n",
    "# Input : outputs/run_001/01_blocks/page_*_blocks.json\n",
    "# Output: outputs/run_001/01a_normalized/page_*_blocks.norm.json\n",
    "# What this does:\n",
    "#   • unify reading order (top→bottom, left→right)\n",
    "#   • adaptive line merge (scaled by median text height)\n",
    "#   • tag (not drop) header/footer regions\n",
    "#   • simple 1/2-column stitching if columns are well-separated\n",
    "#   • PRESERVE structure: keep per-row fragments as `text_lines`\n",
    "# QA printed: counts, character coverage, tags, mode\n",
    "\n",
    "# %%\n",
    "import json, statistics, re, math\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "RUN_ROOT = Path(\"outputs/run_001\").resolve()\n",
    "IN_DIR   = RUN_ROOT / \"01_blocks\"\n",
    "OUT_DIR  = RUN_ROOT / \"01a_normalized\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "assert IN_DIR.exists(), f\"Missing {IN_DIR}\"\n",
    "\n",
    "# ---------------- Tunables ----------------\n",
    "# We *tag* header/footer instead of dropping to avoid accidental losses.\n",
    "DROP_HEADER = False\n",
    "DROP_FOOTER = False\n",
    "\n",
    "# Base merge thresholds (scaled per page by median text height)\n",
    "BASE_LINE_MERGE_TOL_Y = 0.60   # × median text height\n",
    "BASE_LINE_MERGE_TOL_X = 0.90   # × median text height\n",
    "\n",
    "# Header/footer bands (adaptive caps)\n",
    "HEADER_MAX_PX = 140\n",
    "FOOTER_MAX_PX = 120\n",
    "\n",
    "MIN_TEXT_LEN = 2\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def chars(blocks): \n",
    "    return sum(len((b.get(\"text\") or \"\")) for b in blocks)\n",
    "\n",
    "def page_height(blocks: List[Dict[str,Any]]) -> float:\n",
    "    ys = [b[\"bbox\"][3] for b in blocks] + [b[\"bbox\"][1] for b in blocks]\n",
    "    return max(ys) if ys else 842.0\n",
    "\n",
    "def page_width(blocks: List[Dict[str,Any]]) -> float:\n",
    "    xs = [b[\"bbox\"][2] for b in blocks]\n",
    "    return max(xs) if xs else 595.0\n",
    "\n",
    "def block_h(b): \n",
    "    x0,y0,x1,y1 = b[\"bbox\"]; return max(1.0, y1-y0)\n",
    "\n",
    "def is_native(b): \n",
    "    return \"native\" in (b.get(\"source\") or \"\").lower()\n",
    "\n",
    "def detect_handwriting(blocks) -> bool:\n",
    "    \"\"\"Heuristic: few native blocks OR very tall/variable text boxes.\"\"\"\n",
    "    if not blocks: return False\n",
    "    n_native = sum(1 for b in blocks if is_native(b))\n",
    "    ratio_native = n_native / len(blocks)\n",
    "    hts = [block_h(b) for b in blocks]\n",
    "    med_h = statistics.median(hts) if hts else 12\n",
    "    iqr = (statistics.quantiles(hts, n=4)[2] - statistics.quantiles(hts, n=4)[0]) if len(hts) >= 4 else 0\n",
    "    return (ratio_native < 0.35) or (med_h > 22) or (iqr > 18)\n",
    "\n",
    "def adaptive_bands(H: float, handwriting: bool) -> Tuple[float,float]:\n",
    "    \"\"\"(header_px, footer_px). Smaller bands for handwriting pages.\"\"\"\n",
    "    if handwriting:\n",
    "        return min(0.06*H, 70), min(0.05*H, 60)\n",
    "    return min(0.10*H, HEADER_MAX_PX), min(0.08*H, FOOTER_MAX_PX)\n",
    "\n",
    "def safe_text(b) -> str:\n",
    "    return (b.get(\"text\") or \"\").strip()\n",
    "\n",
    "# Soft markers that often start a *new* list item/line even if y-close.\n",
    "_BULLET_START = re.compile(r\"\"\"^\\s*(?:[\\u2022\\u25CF\\u25E6\\-–—→]|\\(?\\d+\\)|[A-Za-z]\\))\\s+\"\"\")\n",
    "\n",
    "def should_force_new_row(prev_txt: str, next_txt: str) -> bool:\n",
    "    \"\"\"Avoid over-merging lists/bullets.\"\"\"\n",
    "    if _BULLET_START.match(next_txt or \"\"):  # next item looks like a bullet/numbered point\n",
    "        return True\n",
    "    # If prev ends with strong stop, keep separate\n",
    "    if prev_txt and prev_txt.rstrip().endswith((\".\", \";\", \":\")):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def merge_rows(blocks, tol_y_px, tol_x_px):\n",
    "    \"\"\"Greedy row assembly with bullet-aware protection.\"\"\"\n",
    "    blocks = sorted(blocks, key=lambda b:(round(b[\"bbox\"][1],1), round(b[\"bbox\"][0],1)))\n",
    "    rows = []\n",
    "    for b in blocks:\n",
    "        t = safe_text(b)\n",
    "        if not t:\n",
    "            continue\n",
    "        x0,y0,x1,y1 = b[\"bbox\"]\n",
    "        cy = 0.5*(y0+y1)\n",
    "        placed = False\n",
    "        for r in rows:\n",
    "            # same baseline?\n",
    "            if abs(cy - r[\"y\"]) <= tol_y_px:\n",
    "                # small horizontal gap?\n",
    "                close_x = (x0 - r[\"xmax\"]) <= tol_x_px\n",
    "                if close_x and not should_force_new_row(r[\"texts\"][-1] if r[\"texts\"] else \"\", t):\n",
    "                    r[\"texts\"].append(t)\n",
    "                    r[\"xmax\"] = max(r[\"xmax\"], x1)\n",
    "                    r[\"bbox\"][0] = min(r[\"bbox\"][0], x0)\n",
    "                    r[\"bbox\"][1] = min(r[\"bbox\"][1], y0)\n",
    "                    r[\"bbox\"][2] = max(r[\"bbox\"][2], x1)\n",
    "                    r[\"bbox\"][3] = max(r[\"bbox\"][3], y1)\n",
    "                    r[\"src\"].append(b)\n",
    "                    placed = True\n",
    "                    break\n",
    "        if not placed:\n",
    "            rows.append({\n",
    "                \"y\": cy, \"xmax\": x1, \"texts\":[t],\n",
    "                \"bbox\":[x0,y0,x1,y1], \"src\":[b]\n",
    "            })\n",
    "    return rows\n",
    "\n",
    "def maybe_two_columns(rows, page_w: float):\n",
    "    \"\"\"Simple 2-cluster on x-centres; only if well separated.\"\"\"\n",
    "    if len(rows) < 8:\n",
    "        return [rows]\n",
    "    xc = [(r[\"bbox\"][0]+r[\"bbox\"][2])/2 for r in rows]\n",
    "    if not xc: \n",
    "        return [rows]\n",
    "    c1, c2 = min(xc), max(xc)\n",
    "    for _ in range(8):\n",
    "        g1, g2 = [], []\n",
    "        for i,x in enumerate(xc):\n",
    "            (g1 if abs(x-c1)<=abs(x-c2) else g2).append(i)\n",
    "        if not g1 or not g2: \n",
    "            break\n",
    "        c1 = sum(xc[i] for i in g1)/len(g1)\n",
    "        c2 = sum(xc[i] for i in g2)/len(g2)\n",
    "    if not g1 or not g2:\n",
    "        return [rows]\n",
    "    sep = abs(c1-c2)/max(1.0, page_w)\n",
    "    if sep < 0.12:\n",
    "        return [rows]\n",
    "    col1 = [rows[i] for i in g1]\n",
    "    col2 = [rows[i] for i in g2]\n",
    "    col1.sort(key=lambda r:(round(r[\"bbox\"][1],1), round(r[\"bbox\"][0],1)))\n",
    "    col2.sort(key=lambda r:(round(r[\"bbox\"][1],1), round(r[\"bbox\"][0],1)))\n",
    "    return [col1, col2]\n",
    "\n",
    "def normalize_page(blocks: List[Dict[str,Any]]) -> Tuple[List[Dict[str,Any]], Dict[str,int]]:\n",
    "    if not blocks:\n",
    "        return [], {\"tag_header\":0,\"tag_footer\":0,\"rows_out\":0,\"mode\":\"none\"}\n",
    "\n",
    "    H = page_height(blocks)\n",
    "    W = page_width(blocks)\n",
    "    handwriting = detect_handwriting(blocks)\n",
    "\n",
    "    # Adaptive tolerances from median height\n",
    "    hts = [block_h(b) for b in blocks]\n",
    "    med_h = statistics.median(hts) if hts else 12\n",
    "    tol_y = max(4.0, BASE_LINE_MERGE_TOL_Y * med_h)\n",
    "    tol_x = max(10.0, BASE_LINE_MERGE_TOL_X * med_h)\n",
    "\n",
    "    head_px, foot_px = adaptive_bands(H, handwriting)\n",
    "    y_head, y_foot = head_px, H - foot_px\n",
    "\n",
    "    tagged_header = tagged_footer = 0\n",
    "    kept = []\n",
    "    for b in blocks:\n",
    "        t = safe_text(b)\n",
    "        if not t:\n",
    "            continue\n",
    "        x0,y0,x1,y1 = b[\"bbox\"]\n",
    "        in_header = (y1 <= y_head)\n",
    "        in_footer = (y0 >= y_foot)\n",
    "        meta = dict(b.get(\"stage_meta\") or {})\n",
    "        if in_header:\n",
    "            meta[\"header_tagged\"] = True\n",
    "            tagged_header += 1\n",
    "            if DROP_HEADER:\n",
    "                continue\n",
    "        if in_footer:\n",
    "            meta[\"footer_tagged\"] = True\n",
    "            tagged_footer += 1\n",
    "            if DROP_FOOTER:\n",
    "                continue\n",
    "        nb = dict(b)\n",
    "        nb[\"stage_meta\"] = meta\n",
    "        kept.append(nb)\n",
    "\n",
    "    # Merge on lines with bullet-aware guard\n",
    "    rows = merge_rows(kept, tol_y, tol_x)\n",
    "\n",
    "    # Column stitching if clearly 2 columns\n",
    "    groups = maybe_two_columns(rows, W)\n",
    "    mode = \"1col\" if len(groups)==1 else \"2col\"\n",
    "\n",
    "    # Emit: keep `text_lines` to preserve structure\n",
    "    out = []\n",
    "    for grp in groups:\n",
    "        for r in grp:\n",
    "            lines = [t for t in r[\"texts\"] if t.strip()]\n",
    "            joined = \" \".join(lines)\n",
    "            if len(joined.strip()) < MIN_TEXT_LEN:\n",
    "                continue\n",
    "            src0 = r[\"src\"][0]\n",
    "            nb = {**src0}\n",
    "            nb[\"bbox\"] = r[\"bbox\"]\n",
    "            nb[\"text\"] = joined\n",
    "            nb[\"text_norm\"] = joined\n",
    "            nb[\"text_lines\"] = lines  # <-- structure preserved\n",
    "            meta = dict(nb.get(\"stage_meta\") or {})\n",
    "            meta.update({\n",
    "                \"line_merge\": True,\n",
    "                \"two_column_mode\": (mode==\"2col\"),\n",
    "                \"median_h\": med_h,\n",
    "                \"tol_y_px\": tol_y,\n",
    "                \"tol_x_px\": tol_x,\n",
    "            })\n",
    "            nb[\"stage_meta\"] = meta\n",
    "            out.append(nb)\n",
    "\n",
    "    # Final order\n",
    "    out.sort(key=lambda b:(round(b[\"bbox\"][1],1), round(b[\"bbox\"][0],1)))\n",
    "    stats = {\"tag_header\":tagged_header, \"tag_footer\":tagged_footer, \"rows_out\":len(out), \"mode\":mode}\n",
    "    return out, stats\n",
    "\n",
    "# ----------------- Run --------------------\n",
    "pages = sorted(IN_DIR.glob(\"page_*_blocks.json\"))\n",
    "assert pages, f\"No page_*_blocks.json in {IN_DIR}\"\n",
    "\n",
    "for p in pages:\n",
    "    data = json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "    c0 = chars(data)\n",
    "    out, st = normalize_page(data)\n",
    "    c1 = chars(out)\n",
    "    cov = (c1/c0*100) if c0 else 100.0\n",
    "\n",
    "    outp = OUT_DIR / f\"{p.stem}.norm.json\"\n",
    "    outp.write_text(json.dumps(out, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    print(f\"✓ {p.name}: in={len(data)} out={len(out)} \"\n",
    "          f\"chars={c1}/{c0} ({cov:.1f}%) \"\n",
    "          f\"tagged(H/F)={st['tag_header']}/{st['tag_footer']} mode={st['mode']}\")\n",
    "\n",
    "print(\"\\n✅ Layout normalization complete →\", OUT_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rxetl)",
   "language": "python",
   "name": "rxetl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
