{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bb79981",
   "metadata": {},
   "source": [
    "\n",
    "# OCR (MCP-first) Pipeline — Notebook\n",
    "\n",
    "This notebook uses **MCP-backed OCR servers** (HTTP `/ocr`) for **Tesseract**, **PaddleOCR**, and **Surya**.  \n",
    "No local OCR engines run inside the kernel — each OCR engine lives in its own process.\n",
    "\n",
    "**What you get:**\n",
    "- 3 server scripts (download below) to run OCR backends:\n",
    "  - `mcp_ocr_tesseract.py` → http://127.0.0.1:8089/ocr\n",
    "  - `mcp_ocr_paddle.py`    → http://127.0.0.1:8090/ocr\n",
    "  - `mcp_ocr_surya.py`     → http://127.0.0.1:8091/ocr\n",
    "- A pipeline that calls these endpoints only (MCP/HTTP), merges blocks, and saves per-page JSON + viz overlays.\n",
    "\n",
    "> Tip: Each server also mounts an **MCP adapter** at `/mcp` if `fastmcp` is installed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2f906b",
   "metadata": {},
   "source": [
    "\n",
    "## 0) Install dependencies (run in a terminal / new cell if needed)\n",
    "\n",
    "```bash\n",
    "# base\n",
    "pip install fastapi uvicorn pillow requests nbformat rapidfuzz\n",
    "\n",
    "# native text extraction (optional but recommended)\n",
    "pip install pymupdf\n",
    "\n",
    "# OCR engines (install what you plan to run as servers)\n",
    "pip install pytesseract\n",
    "# macOS: brew install tesseract tesseract-lang  (or similar)\n",
    "\n",
    "pip install paddleocr  # (or follow PaddlePaddle platform-specific instructions)\n",
    "pip install surya-ocr  # requires torch; CPU-only:\n",
    "pip install -U torch --index-url https://download.pytorch.org/whl/cpu\n",
    "\n",
    "# Optional MCP adapter\n",
    "pip install fastmcp\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f492d2",
   "metadata": {},
   "source": [
    "\n",
    "## 1) (Recommended) Start servers in separate terminals\n",
    "\n",
    "**Terminal A (Tesseract):**\n",
    "```bash\n",
    "python mcp_ocr_tesseract.py  # serves http://127.0.0.1:8089/ocr\n",
    "```\n",
    "\n",
    "**Terminal B (Paddle):**\n",
    "```bash\n",
    "python mcp_ocr_paddle.py     # serves http://127.0.0.1:8090/ocr\n",
    "```\n",
    "\n",
    "**Terminal C (Surya):**\n",
    "```bash\n",
    "python mcp_ocr_surya.py      # serves http://127.0.0.1:8091/ocr\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "359fc27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoints: {'tesseract': 'http://127.0.0.1:8089/ocr', 'paddle': 'http://127.0.0.1:8090/ocr', 'surya': 'http://127.0.0.1:8091/ocr'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2) Config — endpoints & pipeline options\n",
    "MCP_ENDPOINTS = {\n",
    "    \"tesseract\": \"http://127.0.0.1:8089/ocr\",  # set None to disable any\n",
    "    \"paddle\":    \"http://127.0.0.1:8090/ocr\",\n",
    "    \"surya\":     \"http://127.0.0.1:8091/ocr\",\n",
    "}\n",
    "\n",
    "PDF_PATH    = \"input_pdfs/ET1-Adobe Scan 10 Sept 2025.pdf\"  # change me\n",
    "OUTPUT_DIR  = \"outputs/run_mcp/01_blocks\"\n",
    "OCR_LANG    = \"en\"   # 'en','hi','te','mr','ta'\n",
    "\n",
    "# rasterization\n",
    "DPI             = 300\n",
    "MASK_BANNERS    = True\n",
    "BANNER_TOP_PCT  = 0.18\n",
    "BANNER_BOT_PCT  = 0.20\n",
    "\n",
    "# merge/filter\n",
    "MIN_CONF        = 0.50\n",
    "LINE_JOIN_PX    = 14\n",
    "PARA_JOIN_PX    = 26\n",
    "DEDUP_IOU_THR   = 0.50\n",
    "DEDUP_SIM_THR   = 0.92\n",
    "NATIVE_LEN_GATE = 100\n",
    "\n",
    "# viz\n",
    "MAKE_VIZ_PNG    = True\n",
    "\n",
    "from pathlib import Path\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "print(\"Endpoints:\", MCP_ENDPOINTS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8285ca78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) Utilities (native extraction + merge)\n",
    "import json, io, requests, numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from pathlib import Path\n",
    "\n",
    "# Try PyMuPDF; fallback to pdf2image if missing\n",
    "try:\n",
    "    import fitz as _fitz\n",
    "    HAVE_FITZ = True\n",
    "except Exception:\n",
    "    HAVE_FITZ = False\n",
    "\n",
    "def clamp_long_side(pil: Image.Image, max_side:int) -> Image.Image:\n",
    "    w, h = pil.size\n",
    "    s = max(w, h)\n",
    "    if s <= max_side: return pil\n",
    "    scale = max_side / s\n",
    "    return pil.resize((int(w*scale), int(h*scale)))\n",
    "\n",
    "def page_to_image(doc, page_index: int, dpi: int=300) -> Image.Image:\n",
    "    page = doc[page_index]\n",
    "    zoom = dpi / 72\n",
    "    mat  = _fitz.Matrix(zoom, zoom)\n",
    "    pix  = page.get_pixmap(matrix=mat, alpha=False)\n",
    "    return Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "\n",
    "def mask_bands(pil: Image.Image, top_pct: float, bot_pct: float) -> Image.Image:\n",
    "    if not MASK_BANNERS: \n",
    "        return pil\n",
    "    w,h   = pil.size\n",
    "    top_h = int(h * max(0, min(0.45, top_pct)))\n",
    "    bot_h = int(h * max(0, min(0.45, bot_pct)))\n",
    "    out   = pil.copy()\n",
    "    draw  = ImageDraw.Draw(out)\n",
    "    bg = (240,240,240)\n",
    "    if top_h>0: draw.rectangle([0,0,w,top_h], fill=bg)\n",
    "    if bot_h>0: draw.rectangle([0,h-bot_h,w,h], fill=bg)\n",
    "    return out\n",
    "\n",
    "def blocks_sort_key(b):\n",
    "    y0 = round(b[\"bbox\"][1],1); x0 = round(b[\"bbox\"][0],1)\n",
    "    return (y0, x0)\n",
    "\n",
    "def iou(a, b) -> float:\n",
    "    ax0, ay0, ax1, ay1 = a; bx0, by0, bx1, by1 = b\n",
    "    inter_x0 = max(ax0, bx0); inter_y0 = max(ay0, by0)\n",
    "    inter_x1 = min(ax1, bx1); inter_y1 = min(ay1, by1)\n",
    "    iw = max(0.0, inter_x1 - inter_x0); ih = max(0.0, inter_y1 - inter_y0)\n",
    "    inter = iw * ih\n",
    "    if inter <= 0: return 0.0\n",
    "    area_a = (ax1-ax0)*(ay1-ay0); area_b = (bx1-bx0)*(by1-by0)\n",
    "    return inter / max(1e-6, area_a + area_b - inter)\n",
    "\n",
    "# fuzzy sim (dedup)\n",
    "try:\n",
    "    from rapidfuzz.fuzz import ratio as fuzz_ratio\n",
    "except Exception:\n",
    "    from difflib import SequenceMatcher\n",
    "    def fuzz_ratio(a,b): return int(100*SequenceMatcher(None, a, b).ratio())\n",
    "\n",
    "def regroup_lines(blocks, line_gap:int=14, para_gap:int=26):\n",
    "    if not blocks: return []\n",
    "    bs = sorted(blocks, key=blocks_sort_key)\n",
    "    rows, cur = [], [bs[0]]\n",
    "    for b in bs[1:]:\n",
    "        prev = cur[-1]\n",
    "        if abs(b[\"bbox\"][1] - prev[\"bbox\"][1]) <= line_gap:\n",
    "            cur.append(b)\n",
    "        else:\n",
    "            rows.append(cur); cur=[b]\n",
    "    rows.append(cur)\n",
    "\n",
    "    lines=[]\n",
    "    for row in rows:\n",
    "        row = sorted(row, key=lambda x:x[\"bbox\"][0])\n",
    "        text = \" \".join(x[\"text\"] for x in row if x[\"text\"])\n",
    "        x0 = min(x[\"bbox\"][0] for x in row); y0=min(x[\"bbox\"][1] for x in row)\n",
    "        x1 = max(x[\"bbox\"][2] for x in row); y1=max(x[\"bbox\"][3] for x in row)\n",
    "        src= \"+\".join(sorted(set(x[\"source\"] for x in row)))\n",
    "        conf=sum(x.get(\"confidence\",1.0) for x in row)/len(row)\n",
    "        lines.append({\"bbox\":[x0,y0,x1,y1], \"text\":text.strip(), \"source\":src, \"confidence\":conf})\n",
    "\n",
    "    paras=[]\n",
    "    current=[lines[0]]\n",
    "    for ln in lines[1:]:\n",
    "        prev=current[-1]\n",
    "        if abs(ln[\"bbox\"][1]-prev[\"bbox\"][3]) <= para_gap:\n",
    "            current.append(ln)\n",
    "        else:\n",
    "            txt=\" \".join(x[\"text\"] for x in current if x[\"text\"])\n",
    "            x0=min(x[\"bbox\"][0] for x in current); y0=min(x[\"bbox\"][1] for x in current)\n",
    "            x1=max(x[\"bbox\"][2] for x in current); y1=max(x[\"bbox\"][3] for x in current)\n",
    "            src=\"+\".join(sorted(set(\",\".join(x[\"source\"] for x in current).split(\"+\"))))\n",
    "            conf=sum(x.get(\"confidence\",1.0) for x in current)/len(current)\n",
    "            paras.append({\"bbox\":[x0,y0,x1,y1], \"text\":txt.strip(), \"source\":src, \"confidence\":conf})\n",
    "            current=[ln]\n",
    "    if current:\n",
    "        txt=\" \".join(x[\"text\"] for x in current)\n",
    "        x0=min(x[\"bbox\"][0] for x in current); y0=min(x[\"bbox\"][1] for x in current)\n",
    "        x1=max(x[\"bbox\"][2] for x in current); y1=max(x[\"bbox\"][3] for x in current)\n",
    "        src=\"+\".join(sorted(set(\",\".join(x[\"source\"] for x in current).split(\"+\"))))\n",
    "        conf=sum(x.get(\"confidence\",1.0) for x in current)/len(current)\n",
    "        paras.append({\"bbox\":[x0,y0,x1,y1], \"text\":txt.strip(), \"source\":src, \"confidence\":conf})\n",
    "    return paras\n",
    "\n",
    "def deduplicate(blocks, iou_thr:float=0.50, sim_thr:float=0.92):\n",
    "    out=[]\n",
    "    for b in sorted(blocks, key=lambda x: (-x.get(\"confidence\",1.0), len(x.get(\"text\",\"\")))):\n",
    "        t = (b.get(\"text\",\"\") or \"\").strip()\n",
    "        if not t: continue\n",
    "        keep=True\n",
    "        for a in out:\n",
    "            if iou(b[\"bbox\"], a[\"bbox\"]) >= iou_thr:\n",
    "                if fuzz_ratio(t.lower(), a[\"text\"].lower())/100.0 >= sim_thr:\n",
    "                    keep=False; break\n",
    "        if keep: out.append(b)\n",
    "    return sorted(out, key=blocks_sort_key)\n",
    "\n",
    "def merge_ensemble(native, ocrs, page_h:int):\n",
    "    all_blocks = []; all_blocks.extend(native)\n",
    "    for s in ocrs: all_blocks.extend(s)\n",
    "    regrouped = regroup_lines(all_blocks, LINE_JOIN_PX, PARA_JOIN_PX)\n",
    "    deduped   = deduplicate(regrouped, DEDUP_IOU_THR, DEDUP_SIM_THR)\n",
    "    return deduped\n",
    "\n",
    "def extract_native(page):\n",
    "    out = []\n",
    "    for b in page.get_text(\"blocks\"):\n",
    "        if len(b) >= 5:\n",
    "            x0,y0,x1,y1,txt = b[:5]\n",
    "            if txt and str(txt).strip():\n",
    "                out.append({\n",
    "                    \"bbox\":[float(x0),float(y0),float(x1),float(y1)],\n",
    "                    \"text\":str(txt).strip(),\n",
    "                    \"source\":\"native\",\n",
    "                    \"confidence\":1.0\n",
    "                })\n",
    "    return sorted(out, key=blocks_sort_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47c490e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4) Client to call MCP endpoints and normalize blocks\n",
    "def call_mcp(endpoint: str, pil_img: Image.Image, lang=\"en\"):\n",
    "    if not endpoint:\n",
    "        return []\n",
    "    try:\n",
    "        buf = io.BytesIO()\n",
    "        pil_img.save(buf, format=\"PNG\"); buf.seek(0)\n",
    "        r = requests.post(endpoint, data={\"lang\": lang},\n",
    "                          files={\"image\": (\"page.png\", buf.getvalue(), \"image/png\")},\n",
    "                          timeout=60)\n",
    "        r.raise_for_status()\n",
    "        js = r.json()\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] MCP call failed for {endpoint}: {e}\")\n",
    "        return []\n",
    "\n",
    "    blocks = []\n",
    "    # Preferred: {\"blocks\":[{\"text\",\"confidence\",\"bbox\":[x0,y0,x1,y1]}, ...]}\n",
    "    if isinstance(js.get(\"blocks\"), list):\n",
    "        for it in js[\"blocks\"]:\n",
    "            try:\n",
    "                txt = (it.get(\"text\") or \"\").strip()\n",
    "                conf = float(it.get(\"confidence\", 0.0))\n",
    "                box = it.get(\"bbox\") or it.get(\"box\")\n",
    "                if not (txt and box): \n",
    "                    continue\n",
    "                if isinstance(box, (list,tuple)) and len(box)==4:\n",
    "                    x0,y0,x1,y1 = [float(v) for v in box]\n",
    "                else:\n",
    "                    xs = [p[0] for p in box]; ys = [p[1] for p in box]\n",
    "                    x0,y0,x1,y1 = float(min(xs)), float(min(ys)), float(max(xs)), float(max(ys))\n",
    "                blocks.append({\"bbox\":[x0,y0,x1,y1], \"text\":txt, \"confidence\":conf, \"source\":\"paddle_mcp\"})\n",
    "            except Exception:\n",
    "                continue\n",
    "        return blocks\n",
    "\n",
    "    # Fallback: {\"text\":\"...\", \"avg_confidence\":...}\n",
    "    if js.get(\"text\"):\n",
    "        w,h = pil_img.size\n",
    "        conf = float(js.get(\"avg_confidence\", 0.0))\n",
    "        blocks.append({\"bbox\":[0.0,0.0,float(w),float(h)], \"text\":js[\"text\"].strip(), \"confidence\":conf, \"source\":\"paddle_mcp\"})\n",
    "    return blocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2a1f9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] PDF: /Users/balijepalli/Documents/GitHub/entheory-ai/notebooks/input_pdfs/ET1-Adobe Scan 10 Sept 2025.pdf\n",
      "[INFO] Out: /Users/balijepalli/Documents/GitHub/entheory-ai/notebooks/outputs/run_mcp/01_blocks\n",
      "[page 1] native=38 tesseract=79 paddle=0 surya=0 → merged=11\n",
      "[page 2] native=54 tesseract=186 paddle=0 surya=0 → merged=16\n",
      "[page 3] native=14 tesseract=84 paddle=0 surya=0 → merged=25\n",
      "[page 4] native=27 tesseract=71 paddle=0 surya=0 → merged=25\n",
      "✅ Done Extraction → /Users/balijepalli/Documents/GitHub/entheory-ai/notebooks/outputs/run_mcp/01_blocks\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5) Run pipeline (MCP only for OCR)\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "pdf_path = Path(PDF_PATH).expanduser().resolve()\n",
    "out_dir  = Path(OUTPUT_DIR).expanduser().resolve()\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if HAVE_FITZ:\n",
    "    doc = _fitz.open(str(pdf_path))\n",
    "    total_pages = len(doc)\n",
    "else:\n",
    "    try:\n",
    "        from pdf2image import convert_from_path\n",
    "    except Exception:\n",
    "        raise RuntimeError(\"Neither PyMuPDF nor pdf2image available. Install one of them.\")\n",
    "    pages = convert_from_path(str(pdf_path), dpi=DPI)\n",
    "    total_pages = len(pages)\n",
    "\n",
    "meta = {\n",
    "    \"pages\": total_pages,\n",
    "    \"dpi\": DPI,\n",
    "    \"lang\": OCR_LANG,\n",
    "    \"endpoints\": MCP_ENDPOINTS,\n",
    "}\n",
    "(out_dir/\"metadata.json\").write_text(json.dumps(meta, indent=2), encoding=\"utf-8\")\n",
    "print(\"[INFO] PDF:\", pdf_path)\n",
    "print(\"[INFO] Out:\", out_dir)\n",
    "\n",
    "for i in range(total_pages):\n",
    "    # native\n",
    "    if HAVE_FITZ:\n",
    "        page = doc[i]\n",
    "        native = extract_native(page)\n",
    "        pil    = page_to_image(doc, i, dpi=DPI)\n",
    "    else:\n",
    "        native = []\n",
    "        pil = pages[i]\n",
    "\n",
    "    pil_base = mask_bands(pil, BANNER_TOP_PCT, BANNER_BOT_PCT) if MASK_BANNERS else pil\n",
    "\n",
    "    # Call each MCP endpoint configured\n",
    "    heads = []\n",
    "    for name, ep in MCP_ENDPOINTS.items():\n",
    "        if not ep: \n",
    "            continue\n",
    "        bs = call_mcp(ep, pil_base, lang=OCR_LANG)\n",
    "        # tag source by engine name\n",
    "        for b in bs: \n",
    "            b[\"source\"] = name\n",
    "            # conf gate\n",
    "        bs = [b for b in bs if b.get(\"confidence\",0.0) >= MIN_CONF or not b.get(\"confidence\")]\n",
    "        # dump raw\n",
    "        Path(out_dir / f\"page_{i+1:03d}_ocr_{name}.json\").write_text(json.dumps(bs, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "        heads.append(bs)\n",
    "\n",
    "    merged = merge_ensemble(native if (sum(len(b.get('text','')) for b in native) >= NATIVE_LEN_GATE) else [], heads, pil.height)\n",
    "    Path(out_dir / f\"page_{i+1:03d}_blocks.json\").write_text(json.dumps(merged, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "\n",
    "    print(f\"[page {i+1}] native={len(native)} \" + \" \".join(f\"{k}={len(v)}\" for k,v in zip(MCP_ENDPOINTS.keys(), heads)) + f\" → merged={len(merged)}\")\n",
    "\n",
    "    if MAKE_VIZ_PNG:\n",
    "        im = pil.copy()\n",
    "        dr = ImageDraw.Draw(im, \"RGBA\")\n",
    "        for b in merged:\n",
    "            x0,y0,x1,y1 = map(int, b[\"bbox\"])\n",
    "            src = (b.get(\"source\") or \"\").lower()\n",
    "            col = (122,199,136,80)\n",
    "            if \"tesseract\" in src: col=(70,130,180,90)\n",
    "            if \"paddle\"    in src: col=(34,139,34,90)\n",
    "            if \"surya\"     in src: col=(220,20,60,90)\n",
    "            if \"native\"    in src: col=(147,112,219,90)\n",
    "            dr.rectangle([x0,y0,x1,y1], outline=(0,0,0,180), width=2, fill=col)\n",
    "        im.save(out_dir/f\"page_{i+1:03d}_viz.png\")\n",
    "\n",
    "print(\"✅ Done Extraction →\", out_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rxetl)",
   "language": "python",
   "name": "rxetl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
