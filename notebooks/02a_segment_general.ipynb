{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d3c3d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using: 01a_normalized\n",
      "✓ page_001_blocks.norm.json: segments=3 coverage=100.1%\n",
      "✓ page_002_blocks.norm.json: segments=6 coverage=100.1%\n",
      "✓ page_003_blocks.norm.json: segments=4 coverage=100.1%\n",
      "✓ page_004_blocks.norm.json: segments=4 coverage=100.2%\n",
      "\n",
      "✅ Segmentation complete → /Users/balijepalli/Documents/GitHub/entheory-ai/notebooks/outputs/run_001/02a_segmented\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # 02a — General segmentation (gap + heading + bullets)\n",
    "# Input  : outputs/run_001/01a_normalized/page_*_blocks.norm.json  (fallback: 01_blocks)\n",
    "# Output : outputs/run_001/02a_segmented/page_*_blocks.seg.json\n",
    "# QA:\n",
    "#   - segment count, per-segment char totals, coverage % vs normalized\n",
    "\n",
    "# %%\n",
    "import json, re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "RUN_ROOT = Path(\"outputs/run_001\").resolve()\n",
    "IN_DIRS  = [RUN_ROOT/\"01a_normalized\", RUN_ROOT/\"01_blocks\"]\n",
    "OUT_DIR  = RUN_ROOT/\"02a_segmented\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def find_pages():\n",
    "    for d in IN_DIRS:\n",
    "        ps = sorted(d.glob(\"page_*_blocks*.json\"))\n",
    "        if ps:\n",
    "            print(\"[INFO] Using:\", d.name)\n",
    "            return ps, d\n",
    "    raise FileNotFoundError(\"No page_* JSONs in 01a_normalized or 01_blocks\")\n",
    "\n",
    "pages, SRC = find_pages()\n",
    "\n",
    "HEAD_RX = re.compile(r\"^(impression|diagnosis|microscopy|microscopic|gross|clinical details|comment|plan|advice|assessment)\\b[:\\-]?\", re.I)\n",
    "BULLET_RX = re.compile(r\"^(\\-|\\•|•|●|▪|▶|►|\\d+\\)|\\d+\\.)\\s+\")\n",
    "\n",
    "GAP_Y = 18      # gap between paragraphs\n",
    "JOIN_SOFT = True\n",
    "\n",
    "def is_heading(t: str)->bool:\n",
    "    s = t.strip()\n",
    "    if len(s) <= 3: \n",
    "        return False\n",
    "    if HEAD_RX.match(s):\n",
    "        return True\n",
    "    # short ALLCAPS phrase\n",
    "    letters = re.sub(r\"[^A-Za-z]\", \"\", s)\n",
    "    if 3 <= len(letters) <= 24 and letters.isupper():\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def same_para(prev, cur)->bool:\n",
    "    # same paragraph if vertical gap small and not a new heading\n",
    "    if is_heading(cur[\"text\"]): \n",
    "        return False\n",
    "    y_gap = cur[\"bbox\"][1] - prev[\"bbox\"][3]\n",
    "    return y_gap <= GAP_Y\n",
    "\n",
    "def segment_page(blocks: List[Dict[str,Any]]):\n",
    "    # assume already sorted in 01a\n",
    "    segs, cur = [], None\n",
    "    for b in blocks:\n",
    "        txt = (b.get(\"text\") or \"\").strip()\n",
    "        if not txt:\n",
    "            continue\n",
    "\n",
    "        if is_heading(txt):\n",
    "            # start new segment\n",
    "            if cur: \n",
    "                segs.append(cur); cur = None\n",
    "            cur = {\"title\": txt, \"items\": [b], \"bbox\": list(b[\"bbox\"])}\n",
    "            continue\n",
    "\n",
    "        if cur is None:\n",
    "            # first segment (untitled)\n",
    "            cur = {\"title\": None, \"items\": [b], \"bbox\": list(b[\"bbox\"])}\n",
    "        else:\n",
    "            if same_para(cur[\"items\"][-1], b):\n",
    "                # append\n",
    "                cur[\"items\"].append(b)\n",
    "                # expand bbox\n",
    "                x0,y0,x1,y1 = cur[\"bbox\"]\n",
    "                bx0,by0,bx1,by1 = b[\"bbox\"]\n",
    "                cur[\"bbox\"] = [min(x0,bx0), min(y0,by0), max(x1,bx1), max(y1,by1)]\n",
    "            else:\n",
    "                segs.append(cur)\n",
    "                cur = {\"title\": None, \"items\": [b], \"bbox\": list(b[\"bbox\"])}\n",
    "\n",
    "    if cur: \n",
    "        segs.append(cur)\n",
    "\n",
    "    # compact: join text within segments\n",
    "    for s in segs:\n",
    "        lines = [i[\"text\"].strip() for i in s[\"items\"] if i.get(\"text\")]\n",
    "        if JOIN_SOFT:\n",
    "            txt = []\n",
    "            for ln in lines:\n",
    "                if BULLET_RX.match(ln):\n",
    "                    txt.append(\"\\n\" + ln)\n",
    "                else:\n",
    "                    txt.append((\" \" if txt else \"\") + ln)\n",
    "            s[\"text\"] = \"\".join(txt).strip()\n",
    "        else:\n",
    "            s[\"text\"] = \"\\n\".join(lines).strip()\n",
    "\n",
    "    return segs\n",
    "\n",
    "def chars(blocks): return sum(len((b.get(\"text\") or \"\")) for b in blocks)\n",
    "\n",
    "for p in pages:\n",
    "    data = json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "    c0 = chars(data)\n",
    "    segs = segment_page(data)\n",
    "    # save per-page\n",
    "    outp = OUT_DIR / f\"{p.stem}.seg.json\"\n",
    "    outp.write_text(json.dumps(segs, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    c1 = sum(len(s[\"text\"]) for s in segs)\n",
    "    cov = (c1/c0*100) if c0 else 100.0\n",
    "    print(f\"✓ {p.name}: segments={len(segs)} coverage={cov:.1f}%\")\n",
    "\n",
    "print(\"\\n✅ Segmentation complete →\", OUT_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rxetl)",
   "language": "python",
   "name": "rxetl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
