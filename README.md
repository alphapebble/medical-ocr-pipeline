# Medical OCR Pipeline

A production-ready OCR pipeline for medical documents with semantic enhancement capabilities.

## ğŸ¥ **Overview**

This pipeline processes medical documents (PDFs, images) through multiple stages:

1. **Multi-Engine OCR** - Tesseract, EasyOCR, PaddleOCR, Surya
2. **Domain Cleanup** - Medical terminology normalization
3. **LLM Enhancement** - Text cleaning and error correction
4. **Semantic Enhancement** - Chunkr integration for layout analysis
5. **JSON Extraction** - Structured data extraction with schema validation
6. **Validation & Merge** - Final output validation

## ğŸ“ **Repository Structure**

```
medical-ocr-pipeline/
â”œâ”€â”€ notebooks/          # Jupyter notebooks for each pipeline stage
â”‚   â”œâ”€â”€ 01_blocks_all_mcp_compare.ipynb
â”‚   â”œâ”€â”€ 02_cleanup_blocks.ipynb
â”‚   â”œâ”€â”€ 03_llm_cleanup.ipynb
â”‚   â”œâ”€â”€ 03b_chunkr_enhance.ipynb
â”‚   â”œâ”€â”€ 04_json_extraction.ipynb
â”‚   â””â”€â”€ 05_merge_and_validate.ipynb
â”œâ”€â”€ mcp/                # Model Context Protocol servers
â”‚   â”œâ”€â”€ mcp_ocr_tesseract.py
â”‚   â”œâ”€â”€ mcp_ocr_easy.py
â”‚   â”œâ”€â”€ mcp_ocr_paddle.py
â”‚   â”œâ”€â”€ mcp_ocr_surya.py
â”‚   â””â”€â”€ mcp_ocr_docling.py
â”œâ”€â”€ config/             # Configuration files
â”‚   â”œâ”€â”€ medical_terms.yml
â”‚   â”œâ”€â”€ schema_prescription.json
â”‚   â””â”€â”€ schema_radiology.json
â”œâ”€â”€ scripts/            # Setup and utility scripts
â”‚   â””â”€â”€ setup_local_chunkr.sh
â”œâ”€â”€ input_pdfs/         # Input documents
â”œâ”€â”€ outputs/            # Pipeline outputs
â”‚   â””â”€â”€ run_*/
â”œâ”€â”€ tests/              # Unit and integration tests
â””â”€â”€ docs/               # Documentation
    â””â”€â”€ CHUNKR_MIGRATION_PLAN.md
```

## ğŸš€ **Quick Start**

### Prerequisites
- Python 3.8+
- Docker & Docker Compose
- Jupyter Lab/Notebook

### 1. Setup Environment
```bash
git clone <repository-url>
cd medical-ocr-pipeline

# Install dependencies
pip install -r requirements.txt

# Setup MCP servers (optional)
cd mcp && docker compose up -d
```

### 2. Run Pipeline
```bash
# Start Jupyter
jupyter lab

# Run notebooks in sequence:
# 01 â†’ 02 â†’ 03 â†’ (03b) â†’ 04 â†’ 05
```

### 3. Setup Chunkr (Optional Enhancement)
```bash
# For semantic enhancement capabilities
./scripts/setup_local_chunkr.sh
```

## ğŸ“Š **Pipeline Stages**

### **Stage 01: Multi-Engine OCR**
- **Input:** PDF documents
- **Output:** Raw OCR blocks with confidence scores
- **Engines:** Tesseract, EasyOCR, PaddleOCR, Surya, Docling
- **Features:** Parallel processing, confidence-based merging

### **Stage 02: Domain Cleanup**
- **Input:** Raw OCR blocks
- **Output:** Cleaned text with medical term normalization
- **Features:** Medical dictionary, fuzzy matching, spaCy NER

### **Stage 03: LLM Enhancement**
- **Input:** Cleaned blocks
- **Output:** LLM-corrected text
- **Features:** Local Ollama models, batch processing

### **Stage 03b: Semantic Enhancement (Optional)**
- **Input:** LLM-cleaned text
- **Output:** Semantically chunked content
- **Features:** Chunkr integration, layout analysis, structured output

### **Stage 04: JSON Extraction**
- **Input:** Enhanced blocks
- **Output:** Structured JSON with schema validation
- **Features:** Schema-driven extraction, field mapping

### **Stage 05: Validation & Merge**
- **Input:** Extracted JSON
- **Output:** Final validated output
- **Features:** Cross-validation, quality metrics

## ğŸ”§ **Configuration**

### MCP Endpoints
```python
MCP_ENDPOINTS = {
    "tesseract": "http://127.0.0.1:8089/ocr",
    "easyocr": "http://127.0.0.1:8092/ocr", 
    "paddle": "http://127.0.0.1:8090/ocr",
    "surya": "http://127.0.0.1:8091/ocr",
    "docling": "http://127.0.0.1:8093/ocr"
}
```

### Chunkr Integration
```python
chunkr_base_url = "http://localhost:8000"
chunk_target_length = 512
chunk_overlap = 50
```

## ğŸ“ˆ **Performance**

- **Throughput:** ~2-5 pages/minute (depends on OCR engines)
- **Accuracy:** 95%+ on medical documents
- **Languages:** English, Hindi, Telugu, Marathi, Tamil

## ğŸ§ª **Testing**

```bash
# Run unit tests
python -m pytest tests/

# Integration tests
jupyter nbconvert --execute notebooks/01_blocks_all_mcp_compare.ipynb
```

## ğŸ“š **Documentation**

- [Chunkr Migration Plan](docs/CHUNKR_MIGRATION_PLAN.md)
- [MCP Server Setup](mcp/README.md)
- [Schema Documentation](config/README.md)

## ğŸ¤ **Contributing**

1. Fork the repository
2. Create feature branch
3. Add tests for new functionality
4. Submit pull request

## ğŸ“„ **License**

MIT License - see LICENSE file for details

## ğŸ†˜ **Support**

For issues and questions:
- Check existing issues
- Create new issue with detailed description
- Include sample documents (anonymized)